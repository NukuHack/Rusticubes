
use crate::block::{math::ChunkCoord, main::Chunk};
use crate::world::main::World;
use std::{
	cmp::Ordering as CmpOrdering,
	sync::{atomic::Ordering, Arc},
	thread,
};

/// A chunk with priority information for loading order
#[derive(Debug, Clone, Eq, Copy)]
pub struct PriorityChunk {
	coord: ChunkCoord,
	distance_sq: i32,
}
impl PriorityChunk {
	/// Creates a new PriorityChunk with calculated distance from center
	pub fn new(coord: ChunkCoord, center: ChunkCoord) -> Self {
		let (x, y, z) = coord.unpack();
		let (cx, cy, cz) = center.unpack();
		let dx = x - cx;
		let dy = y - cy;
		let dz = z - cz;
		
		Self {
			coord,
			distance_sq: dx * dx + dy * dy + dz * dz,
		}
	}
}
impl PartialEq for PriorityChunk {
	fn eq(&self, other: &Self) -> bool {
		self.distance_sq == other.distance_sq
	}
}
impl PartialOrd for PriorityChunk {
	fn partial_cmp(&self, other: &Self) -> Option<CmpOrdering> {
		Some(self.cmp(other))
	}
}
impl Ord for PriorityChunk {
	fn cmp(&self, other: &Self) -> CmpOrdering {
		// Reverse ordering for min-heap (closest chunks first)
		other.distance_sq.cmp(&self.distance_sq)
	}
}

impl World {
	/// Starts chunk generation threads
	pub fn start_generation_threads(&mut self, thread_count: u8) {
		if self.generation_threads_running.load(Ordering::Relaxed) {
			return; // Already running
		}

		self.generation_threads_running.store(true, Ordering::Relaxed);
		self.set_thread_count(thread_count);
		self.active_workers.store(0, Ordering::Relaxed);
		
		for _ in 0..thread_count {
			let queue = Arc::clone(&self.chunk_generation_queue);
			let sender = self.chunk_generation_sender.clone();
			let running = Arc::clone(&self.generation_threads_running);
			let active_workers = Arc::clone(&self.active_workers);
			let seed = self.seed();
			
			thread::spawn(move || {
				active_workers.fetch_add(1, Ordering::Relaxed);
				
				while running.load(Ordering::Relaxed) {
					// Try to get work without blocking first
					let priority_chunk = {
						let mut queue = match queue.try_lock() {
							Ok(q) => q,
							Err(_) => {
								// Couldn't get lock, try again after short sleep
								thread::sleep(std::time::Duration::from_micros(10));
								continue;
							}
						};
						queue.pop()
					};
					
					if let Some(priority_chunk) = priority_chunk {
						let chunk = Chunk::generate(priority_chunk.coord, seed);
						
						// Non-blocking send attempt
						if let Err(e) = sender.try_send((priority_chunk.coord, chunk)) {
							if e.is_disconnected() {
								break; // Channel disconnected
							}
							// Full channel, put the chunk back in queue and sleep
							queue.lock().unwrap().push(priority_chunk);
							thread::sleep(std::time::Duration::from_millis(1));
						}
					} else {
						// No work, sleep to avoid busy waiting but not too long
						thread::sleep(std::time::Duration::from_millis(1));
					}
				}
				
				active_workers.fetch_sub(1, Ordering::Relaxed);
			});
		}
	}

	#[inline]
	pub fn stop_generation_threads(&self) {
		self.generation_threads_running.store(false, Ordering::Relaxed);
	}
	
	/// Queues a chunk for generation
	#[inline] pub fn generate_chunk(&mut self, chunk: PriorityChunk) {
		if !self.loaded_chunks.insert(chunk.coord) { return; } // Skip if already loaded
		
		let mut queue = match self.chunk_generation_queue.try_lock() {
			Ok(q) => q,
			Err(_) => {
				// Couldn't get lock, skip this chunk for now
				self.loaded_chunks.remove(&chunk.coord);
				return;
			}
		};
		
		// Avoid duplicates in the queue
		if !queue.iter().any(|c| c.coord == chunk.coord) {
			queue.push(chunk);
		}
	}

	/// Processes any chunks generated by worker threads
	#[inline] pub fn process_generated_chunks(&mut self) {
		// Process all available chunks without blocking
		while let Ok((coord, chunk)) = self.generated_chunks_receiver.try_recv() {
			if !self.loaded_chunks.contains(&coord) { continue; }

			self.set_adjacent_un_final(coord);
			self.chunks.insert(coord, chunk);
			self.create_bind_group(coord);
		}
	}
}
